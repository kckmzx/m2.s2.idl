{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP: CNN for Binary Classification (1 vs 8)\n",
    "\n",
    "_From [Dataflowr Module 6](https://dataflowr.github.io/website/modules/6-convolutional-neural-network/) by Marc Lelarge_\n",
    "\n",
    "In this practical, you will build a Convolutional Neural Network (CNN) that learns filter weights to classify MNIST digits (1 vs 8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = (\n",
    "    \"cuda:0\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot multiple images\n",
    "def plots(ims, interp=False, titles=None):\n",
    "    if isinstance(ims, torch.Tensor):\n",
    "        ims = ims.cpu().numpy()\n",
    "    elif isinstance(ims, list) and len(ims) > 0 and isinstance(ims[0], torch.Tensor):\n",
    "        ims = torch.stack(ims).cpu().numpy()\n",
    "    mn, mx = ims.min(), ims.max()\n",
    "    f = plt.figure(figsize=(12, 24))\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(1, len(ims), i + 1)\n",
    "        if not titles is None:\n",
    "            sp.set_title(titles[i], fontsize=18)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else \"none\", vmin=mn, vmax=mx)\n",
    "\n",
    "\n",
    "# plot a single image\n",
    "def plot(im, interp=False):\n",
    "    if isinstance(im, torch.Tensor):\n",
    "        im = im.cpu().numpy()\n",
    "    f = plt.figure(figsize=(3, 6), frameon=True)\n",
    "    plt.imshow(im, interpolation=None if interp else \"none\")\n",
    "\n",
    "\n",
    "plt.gray()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([60000, 28, 28])\n",
      "Labels shape: torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"./data/MNIST/\"\n",
    "train_set = torchvision.datasets.MNIST(root=root_dir, train=True, download=True)\n",
    "\n",
    "# Extract images and labels\n",
    "images = train_set.data.float() / 255\n",
    "labels = train_set.targets\n",
    "\n",
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code implement a data loader for the train set and the test set. No modification is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eights = torch.stack([i for (i, l) in zip(images, labels) if l == 8])\n",
    "ones = torch.stack([i for (i, l) in zip(images, labels) if l == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "\n",
    "l8 = torch.tensor(0, dtype=torch.long)\n",
    "eights_dataset = [[e.unsqueeze(0), l8] for e in eights]\n",
    "l1 = torch.tensor(1, dtype=torch.long)\n",
    "ones_dataset = [[e.unsqueeze(0), l1] for e in ones]\n",
    "train_dataset = eights_dataset[1000:] + ones_dataset[1000:]\n",
    "test_dataset = eights_dataset[:1000] + ones_dataset[:1000]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Building a CNN\n",
    "\n",
    "You will build a neural network that learns the weights of convolutional filters.\n",
    "\n",
    "### Architecture:\n",
    "\n",
    "The network should have:\n",
    "1. **Convolutional layer**: 8 filters of size 3×3 (input: 1 channel, output: 8 channels)\n",
    "2. **Max Pooling layer**: kernel size 7×7, stride 7 (reduces 28×28 to 4×4)\n",
    "3. **Flatten**: converts [batch, 8, 4, 4] to [batch, 128]\n",
    "4. **Linear layer**: maps 128 features to 2 classes (1 vs 8)\n",
    "\n",
    "### TODO:\n",
    "\n",
    "Complete the CNN class below. You'll need to:\n",
    "- Set the correct `padding` value for the convolutional layer\n",
    "- Implement the `forward` method with the correct sequence of operations\n",
    "\n",
    "**Hints:**\n",
    "- Use `F.max_pool2d(x, kernel_size=7, stride=7)` for max pooling\n",
    "- Use `F.log_softmax(x, dim=1)` for the final output (works with NLLLoss)\n",
    "- Don't forget to flatten between pooling and the linear layer!\n",
    "\n",
    "**Documentation:**\n",
    "- [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "- [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
    "- [F.max_pool2d](https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool2d.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(classifier, self).__init__()\n",
    "        # TODO: fill the missing padding value\n",
    "        # Hint: what padding keeps the spatial dimensions unchanged?\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(in_features=128, out_features=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement your network here\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, kernel_size=7, stride=7)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your model\n",
    "\n",
    "Create an instance and test with a batch of 3 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "conv_class = classifier()\n",
    "print(conv_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 1, 28, 28])\n",
      "Output shape: torch.Size([3, 2])\n",
      "Output:\n",
      "tensor([[  0.0000, -71.7371],\n",
      "        [  0.0000, -57.7277],\n",
      "        [-27.3115,   0.0000]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test with a batch of 3 images\n",
    "batch_3images = train_set.data[0:3].float().unsqueeze(1)\n",
    "output = conv_class(batch_3images)\n",
    "print(f\"Input shape: {batch_3images.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output:\\n{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the Training Loop\n",
    "\n",
    "Complete the training function below.\n",
    "\n",
    "**Hints:**\n",
    "- Use `model.train(True)` to set the model to training mode\n",
    "- For each batch:\n",
    "  1. Zero the gradients: `optimizer.zero_grad()`\n",
    "  2. Forward pass: `outputs = model(inputs)`\n",
    "  3. Compute loss: `loss = loss_fn(outputs, labels)`\n",
    "  4. Backward pass: `loss.backward()`\n",
    "  5. Update weights: `optimizer.step()`\n",
    "- Track running loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, loss_fn, optimizer, n_epochs=1):\n",
    "    model.train(True)\n",
    "    loss_train = torch.zeros(n_epochs)\n",
    "    acc_train = torch.zeros(n_epochs)\n",
    "\n",
    "    for epoch_num in range(n_epochs):\n",
    "        running_corrects = 0.0\n",
    "        running_loss = 0.0\n",
    "        size = 0\n",
    "\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            bs = labels.size(0)\n",
    "\n",
    "            # TODO: Implement the training step\n",
    "            # 1. Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 2. Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # 3. Compute loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # 4. Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # 5. Optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            # 6. Track statistics (running_loss and running_corrects)\n",
    "            # Hint: use torch.max(outputs, 1) to get predictions\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * bs\n",
    "            running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "            size += bs\n",
    "\n",
    "        epoch_loss = running_loss / size\n",
    "        epoch_acc = running_corrects / size\n",
    "        loss_train[epoch_num] = epoch_loss\n",
    "        acc_train[epoch_num] = epoch_acc\n",
    "        print(\n",
    "            f\"Epoch {epoch_num+1}/{n_epochs} - Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "    return loss_train, acc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Loss and Optimizer\n",
    "\n",
    "Choose appropriate loss function and optimizer:\n",
    "- For multi-class classification with log_softmax output, what do we need?\n",
    "- Start with SGD optimizer with learning rate 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_class = classifier()\n",
    "\n",
    "# TODO: Choose the appropriate loss function\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "# TODO: Create SGD optimizer with learning_rate=1e-3\n",
    "learning_rate = 1e-3\n",
    "optimizer_cl = torch.optim.SGD(conv_class.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 0.6738 Acc: 0.5783\n",
      "Epoch 2/10 - Loss: 0.6334 Acc: 0.8213\n",
      "Epoch 3/10 - Loss: 0.5986 Acc: 0.8688\n",
      "Epoch 4/10 - Loss: 0.5664 Acc: 0.8900\n",
      "Epoch 5/10 - Loss: 0.5363 Acc: 0.8978\n",
      "Epoch 6/10 - Loss: 0.5081 Acc: 0.9072\n",
      "Epoch 7/10 - Loss: 0.4816 Acc: 0.9093\n",
      "Epoch 8/10 - Loss: 0.4567 Acc: 0.9152\n",
      "Epoch 9/10 - Loss: 0.4334 Acc: 0.9209\n",
      "Epoch 10/10 - Loss: 0.4117 Acc: 0.9261\n"
     ]
    }
   ],
   "source": [
    "l_t, a_t = train(conv_class, train_loader, loss_fn, optimizer_cl, n_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Function\n",
    "\n",
    "Evaluate the model on the test set.\n",
    "\n",
    "**Hints:**\n",
    "- Use `model.train(False)` or `model.eval()` to set evaluation mode\n",
    "- Use `torch.no_grad()` to disable gradient computation\n",
    "- Calculate test loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, loss_fn):\n",
    "    model.train(False)\n",
    "\n",
    "    running_corrects = 0.0\n",
    "    running_loss = 0.0\n",
    "    size = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            bs = labels.size(0)\n",
    "\n",
    "            # TODO: Implement testing\n",
    "            # 1. Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # 2. Compute loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # 3. Track statistics (running_loss and running_corrects)\n",
    "            # Hint: use torch.max(outputs, 1) to get predictions\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * bs\n",
    "            running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "            size += bs\n",
    "\n",
    "    print(\n",
    "        f\"Test - Loss: {running_loss / size:.4f} Acc: {running_corrects / size:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Loss: 0.3981 Acc: 0.9305\n"
     ]
    }
   ],
   "source": [
    "test(conv_class, test_loader, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try [Adam](https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimizer instead of SGD.\n",
    "\n",
    "Reset the model and try training with Adam optimizer instead of SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a new model and train with Adam optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many parameters did your network learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze learned filters\n",
    "\n",
    "Let's visualize what the network learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in conv_class.parameters())\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "\n",
    "# Break down by layer\n",
    "for name, param in conv_class.named_parameters():\n",
    "    print(f\"{name}: {param.numel()} parameters, shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View learned filters\n",
    "for m in conv_class.children():\n",
    "    print(\"Weights:\", m.weight.data)\n",
    "    print(\"Bias:\", m.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and visualize the 8 learned filters\n",
    "T_w = conv_class.conv1.weight.data\n",
    "T_b = conv_class.conv1.bias.data\n",
    "\n",
    "# Plot the 8 learned 3x3 filters\n",
    "plots([T_w[i][0] for i in range(8)], titles=[f\"Filter {i}\" for i in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
